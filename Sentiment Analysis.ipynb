{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b746c1bb",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1764df6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Disable all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6fc7067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # Provides functions for interacting with the operating system\n",
    "import pandas as pd  # Offers data structures and data analysis tools for Python\n",
    "import numpy as np  # Provides support for large, multi-dimensional arrays and matrices\n",
    "import re  # Supplies regular expression matching operations\n",
    "from collections import Counter  # Implements a counter for counting hashable objects\n",
    "from nltk.tokenize import word_tokenize  # Tokenizes text into words\n",
    "from nltk.corpus import stopwords  # Contains a list of common stop words in various languages\n",
    "from gensim.models import Word2Vec  # Implements the Word2Vec algorithm for word embeddings\n",
    "from arabert.preprocess import ArabertPreprocessor  # Preprocesses Arabic text for NLP tasks\n",
    "from gensim.models import KeyedVectors  # Loads and works with pre-trained word vectors\n",
    "import matplotlib.pyplot as plt  # Provides a MATLAB-like plotting framework\n",
    "from sklearn.model_selection import train_test_split  # Splits arrays or matrices into random train and test subsets\n",
    "from sklearn.feature_extraction.text import CountVectorizer  # Converts a collection of text documents to a matrix of token counts\n",
    "from sklearn.metrics.pairwise import cosine_similarity  # Computes the cosine similarity between samples\n",
    "from sklearn.manifold import TSNE  # Provides tools for dimensionality reduction\n",
    "from transformers import AutoTokenizer, AutoModel  # Offers pre-trained models and tokenizers for NLP tasks\n",
    "import torch  # Provides an optimized tensor library for deep learning\n",
    "from sklearn.preprocessing import LabelEncoder  # Encodes target labels with value between 0 and n_classes-1\n",
    "from sklearn.neural_network import MLPClassifier  # Implements a multi-layer perceptron (MLP) algorithm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score  # Provides metrics to evaluate classification performance\n",
    "from sklearn.metrics import classification_report  # Generates a text report showing main classification metrics\n",
    "from keras.models import Sequential  # Allows creating a sequential neural network model\n",
    "from keras.layers import LSTM, Dense, Dropout  # Provides layers for LSTM networks, dense layers, and dropout regularization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce15997",
   "metadata": {},
   "source": [
    "# Load and Combine the Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e908018d",
   "metadata": {},
   "source": [
    "1- Load the provided TSV files.\n",
    "\n",
    "2- Combine positive and negative samples.\n",
    "\n",
    "3- Split the training data into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b398a87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(data_dir, num_samples=2500):\n",
    "    \n",
    "    # Define directories for negative and positive data\n",
    "    neg_dir = os.path.join(data_dir, 'neg')\n",
    "    pos_dir = os.path.join(data_dir, 'pos')\n",
    "    \n",
    "    # Get filenames for negative and positive samples\n",
    "    neg_files = os.listdir(neg_dir)[:num_samples//2]\n",
    "    pos_files = os.listdir(pos_dir)[:num_samples//2]\n",
    "    \n",
    "    # Read data from files\n",
    "    neg_data = [open(os.path.join(neg_dir, file), 'r', encoding='utf-8').read() for file in neg_files]\n",
    "    pos_data = [open(os.path.join(pos_dir, file), 'r', encoding='utf-8').read() for file in pos_files]\n",
    "    \n",
    "    # Create DataFrames for negative and positive data\n",
    "    df_neg = pd.DataFrame({'text': neg_data, 'sentiment': ['negative']*len(neg_data)})\n",
    "    df_pos = pd.DataFrame({'text': pos_data, 'sentiment': ['positive']*len(pos_data)})\n",
    "    \n",
    "    # Concatenate and reset the index of DataFrames\n",
    "    return pd.concat([df_neg, df_pos]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc2b51f",
   "metadata": {},
   "source": [
    "# Step 2: Tokenize the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a13fd87",
   "metadata": {},
   "source": [
    "Step 2.1: Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb7be952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548f11a3",
   "metadata": {},
   "source": [
    " Step 2.2: Remove of Punctuation, Diacritical Marks(Ø§Ù„ØªØ´ÙƒÙŠÙ„), Numbers, and Non-Arabic Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f419d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tokens(tokens):\n",
    "    arabic_tokens = [word for word in tokens if re.match(r'^[\\u0600-\\u06FF]+$', word)]\n",
    "    cleaned_tokens = [re.sub(arabic_punctuation, '', word) for word in arabic_tokens]\n",
    "    cleaned_tokens = [re.sub(arabic_diacritics, '', word) for word in cleaned_tokens]\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf62c84f",
   "metadata": {},
   "source": [
    "Step 2.3: Data representation using BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4081ba42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def represent_data_with_bow(data):\n",
    "    # Initialize CountVectorizer with custom tokenizer and preprocessor that do nothing\n",
    "    vectorizer = CountVectorizer(tokenizer=lambda x: x, preprocessor=lambda x: x)\n",
    "    \n",
    "    # Fit and transform the 'tokens' column of the input data to a sparse matrix\n",
    "    X = vectorizer.fit_transform(data['tokens'])\n",
    "    \n",
    "    # Convert the sparse matrix to a dense DataFrame with token names as columns\n",
    "    bow_representation = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "    \n",
    "    # Return the BoW DataFrame and the fitted vectorizer\n",
    "    return bow_representation, vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee134f9",
   "metadata": {},
   "source": [
    "Step 2.4: Data representation function using arabert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2a5e784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def represent_data_with_arabert(data, tokenizer, model):\n",
    "    embeddings = []  # List to store sentence embeddings\n",
    "    all_words = []  # List to store sentences\n",
    "\n",
    "    for w_tokens in data['tokens']:\n",
    "        sentence = ' '.join(w_tokens)  # Join tokens to form a sentence\n",
    "        inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True)  # Tokenize the sentence\n",
    "        outputs = model(**inputs)  # Get model outputs\n",
    "        embedding = outputs.last_hidden_state.mean(dim=1).squeeze().detach().numpy()  # Compute mean embedding\n",
    "        embeddings.append(embedding)  # Append embedding to list\n",
    "        all_words.append(sentence)  # Append sentence to list\n",
    "    \n",
    "    return embeddings, all_words  # Return embeddings and sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1b19ab",
   "metadata": {},
   "source": [
    "Step 2.5: Print the most similar words using BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2a67110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_similar_words_bow(word, bow_vectorizer, bow_representation):\n",
    "    \n",
    "    # Check if the word is in the BoW vocabulary\n",
    "    if word not in bow_vectorizer.get_feature_names_out():\n",
    "        print(f\"'{word}' not found in the BoW vocabulary.\")\n",
    "        return\n",
    "    \n",
    "    # Get the index of the word in the vocabulary\n",
    "    word_index = bow_vectorizer.vocabulary_[word]\n",
    "    \n",
    "    # Get the word's vector from the BoW representation\n",
    "    word_vector = bow_representation.iloc[:, word_index].values.reshape(1, -1)\n",
    "    \n",
    "    # Calculate cosine similarities between the word vector and all other vectors\n",
    "    similarities = cosine_similarity(word_vector, bow_representation.T)\n",
    "    \n",
    "    # Get indices of the top 5 most similar words (excluding the word itself)\n",
    "    most_similar_indices = similarities.argsort()[0][-6:-1]\n",
    "    \n",
    "    # Get the most similar words using the indices\n",
    "    most_similar_words = [bow_vectorizer.get_feature_names_out()[idx] for idx in most_similar_indices]\n",
    "    \n",
    "    # Print the most similar words\n",
    "    print(f\"Most similar words to '{word}' using BoW:\")\n",
    "    for w in most_similar_words:\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46332778",
   "metadata": {},
   "source": [
    "Step 2.6: Print the most similar words using AraBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78dccb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_similar_words(word, embeddings, all_words, tokenizer, model):\n",
    "    try:\n",
    "        # Tokenize the word and get its embedding\n",
    "        inputs = tokenizer(word, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        outputs = model(**inputs)\n",
    "        word_embedding = outputs.last_hidden_state.mean(dim=1).squeeze().detach().numpy()\n",
    "        \n",
    "        # Convert embeddings list to numpy array\n",
    "        embeddings_array = np.array(embeddings)\n",
    "        \n",
    "        # Calculate cosine similarities between the word embedding and all embeddings\n",
    "        similarities = cosine_similarity(word_embedding.reshape(1, -1), embeddings_array)\n",
    "        \n",
    "        # Get indices of the top 5 most similar words (excluding the word itself)\n",
    "        most_similar_indices = similarities.argsort()[0][-6:-1]\n",
    "        \n",
    "        # Get the most similar words using the indices\n",
    "        most_similar_words = [all_words[idx] for idx in most_similar_indices]\n",
    "        \n",
    "        # Print the most similar words\n",
    "        print(f\"Most similar words to '{word}':\")\n",
    "        for w in most_similar_words:\n",
    "            print(w)\n",
    "    except KeyError:\n",
    "        # Handle the case where the word is not found in the vocabulary\n",
    "        print(f\"'{word}' not found in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfb85be",
   "metadata": {},
   "source": [
    "Step 2.7: Plot and visualize the embedding and their similarities using BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdf2e4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_embeddings_bow(words, vectorizer):\n",
    "    \n",
    "    word_vectors = []\n",
    "    \n",
    "    # Iterate over each word\n",
    "    for word in words:\n",
    "        # Check if the word is in the BoW vocabulary\n",
    "        if word in vectorizer.get_feature_names_out():\n",
    "            # If found, transform the word to its vector representation and append to the list\n",
    "            word_vectors.append(vectorizer.transform([word]).toarray().flatten())\n",
    "    \n",
    "    # Check if any word vectors were found\n",
    "    if not word_vectors:\n",
    "        print(\"No words found in the BoW vocabulary for visualization.\")\n",
    "        return\n",
    "\n",
    "    # Convert the list of word vectors to a numpy array\n",
    "    vectors = np.array(word_vectors)\n",
    "    \n",
    "    # Initialize t-SNE model with specific parameters\n",
    "    tsne_model = TSNE(perplexity=2, n_components=2, init='pca', n_iter=2500, random_state=23)  # Further reduce perplexity\n",
    "    \n",
    "    # Fit and transform the word vectors using t-SNE\n",
    "    new_values = tsne_model.fit_transform(vectors)\n",
    "\n",
    "    # Extract x and y coordinates from the transformed values\n",
    "    x = [value[0] for value in new_values]\n",
    "    y = [value[1] for value in new_values]\n",
    "\n",
    "    # Plot the scatter plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i], y[i])\n",
    "        # Annotate each point with its corresponding word\n",
    "        plt.annotate(words[i],\n",
    "                     xy=(x[i], y[i]),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9684acd",
   "metadata": {},
   "source": [
    "Step 2.8: Plot and visualize the embedding and their similarities using AraBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fdda1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_embeddings(words, embeddings, tokenizer, model):\n",
    "    word_embeddings = []\n",
    "    \n",
    "    # Iterate over each word\n",
    "    for word in words:\n",
    "        # Tokenize the word and get its embedding\n",
    "        inputs = tokenizer(word, return_tensors=\"pt\")\n",
    "        outputs = model(**inputs)\n",
    "        word_embedding = outputs.last_hidden_state.mean(dim=1).squeeze().detach().numpy()\n",
    "        word_embeddings.append(word_embedding)\n",
    "    \n",
    "    # Convert the list of word embeddings to a numpy array\n",
    "    vectors = np.array(word_embeddings)\n",
    "    \n",
    "    # Initialize t-SNE model with specific parameters\n",
    "    tsne_model = TSNE(perplexity=2, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
    "    \n",
    "    # Fit and transform the word embeddings using t-SNE\n",
    "    new_values = tsne_model.fit_transform(vectors)\n",
    "\n",
    "    # Extract x and y coordinates from the transformed values\n",
    "    x = [value[0] for value in new_values]\n",
    "    y = [value[1] for value in new_values]\n",
    "\n",
    "    # Plot the scatter plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i], y[i])\n",
    "        # Annotate each point with its corresponding word\n",
    "        plt.annotate(words[i],\n",
    "                     xy=(x[i], y[i]),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6cc321",
   "metadata": {},
   "source": [
    "# Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cf7e945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ø§Ø¹ØªØ±Ù Ø§Ù† Ø¨ØªØ³ ÙƒØ§Ù†Ùˆ Ø´ÙˆÙŠ Ø´ÙˆÙŠ ÙŠØ¬ÙŠØ¨Ùˆ Ø±Ø§Ø³ÙŠ Ù„ÙƒÙ† Ø§Ù„ÙŠÙˆÙ…...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ØªÙˆÙ‚Ø¹Øª Ø§Ø°Ø§ Ø¬Ø§Øª Ø¯Ø§Ø±ÙŠØ§ Ø¨Ø´ÙˆÙÙ‡Ù… ÙƒØ§Ù…Ù„ÙŠÙ† Ø¨Ø³ Ù„ÙŠ Ù„Ù„Ø­ÙŠÙ† ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ù„Ùˆ Ø¨ÙŠØ¯ÙŠ Ø£Ø±Ø¬Ø¹ Ø³Ø§Ø¹ØªÙŠ ÙˆÙŠÙ† Ø£Ø±Ø¬Ø¹ØŸ Ø¥Ù„ÙŠØ§ ØµØ¯ÙÙ‡ØŸ ÙˆØ§Ù„Ù„Ù‡ ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ğŸ’¥ Ø­Ù…Ø¯Ø§ Ù„Ù„Ù‡ .. Ø§Ù„Ù‚ÙŠØ§Ø¯Ø© ÙƒÙ…Ø§ Ù‡ÙŠ ÙˆØ§Ù„Ø§Ø¹Ø¯Ø§Ø¯ ÙÙŠ ØªØ²Ø§ÙŠØ¯...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#Ø§Ù„Ù‡Ù„Ø§Ù„_Ø§Ù„Ø§Ù‡Ù„ÙŠ Ù…Ø¨Ø±ÙˆÙƒ Ù„Ù„Ù‡Ù„Ø§Ù„ Ù‡Ø§Ø±Ø¯Ù„Ùƒ Ù„Ù„Ø·Ø­Ø§Ù„Ø¨ ğŸ¸ Ùˆ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>Ø£Ø­Ø¨ Ù†ÙØ³ÙƒØŒ Ø£Ø¹Ø´Ù‚Ù‡Ø§ ÙˆØ¯Ù„Ù„Ù‡Ø§ .. ÙØªØ´ Ø¹Ù† Ø§Ù„Ø³Ø¹Ø§Ø¯Ø© Ø³ØªØ¬Ø¯...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>Ø¨Ù…Ù†Ø§Ø³Ø¨Ø© ÙÙˆØ² Ø§Ù„Ù‡Ù„Ø§Ù„ .. ğŸ’™ Ø³Ø­Ø¨ Ø¹Ù„Ù‰ Ø¢ÙŠÙÙˆÙ† XRğŸ“± Ø±ØªÙˆÙŠ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>#ÙˆØ´_ÙŠÙ‚ÙˆÙ„_Ø§Ù„Ù„ÙŠÙ„ ÙŠÙ‚ÙˆÙ„ Ø§Ø±Ù‚Ø¯ÙŠ ÙˆÙÙƒÙŠ Ø§Ù„Ù…Ø³Ù„Ù…ÙŠÙ† Ø´Ø±Ùƒ ğŸŒš ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Ø§Ù„Ù„Ù‡Ù… Ø§Ù†Ùƒ ØªØ±Ù‰ Ù…Ø§ Ù„Ø§ Ù†Ø±Ù‰ ÙˆØªØ¹Ù„Ù… Ù…Ø§ Ù„Ø§ Ù†Ø¹Ù„Ù… ÙØ§ÙƒÙÙ†...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>[ â˜† ] : ÙˆÙ† Ø°Ø§ Ù†Ø§ÙŠÙ† Ù…Ù† Ø§Ù„ÙØ§Ù†Ù…ÙŠØªÙ†Ù‚ .\\n</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text sentiment\n",
       "0     Ø§Ø¹ØªØ±Ù Ø§Ù† Ø¨ØªØ³ ÙƒØ§Ù†Ùˆ Ø´ÙˆÙŠ Ø´ÙˆÙŠ ÙŠØ¬ÙŠØ¨Ùˆ Ø±Ø§Ø³ÙŠ Ù„ÙƒÙ† Ø§Ù„ÙŠÙˆÙ…...  negative\n",
       "1     ØªÙˆÙ‚Ø¹Øª Ø§Ø°Ø§ Ø¬Ø§Øª Ø¯Ø§Ø±ÙŠØ§ Ø¨Ø´ÙˆÙÙ‡Ù… ÙƒØ§Ù…Ù„ÙŠÙ† Ø¨Ø³ Ù„ÙŠ Ù„Ù„Ø­ÙŠÙ† ...  negative\n",
       "2     Ù„Ùˆ Ø¨ÙŠØ¯ÙŠ Ø£Ø±Ø¬Ø¹ Ø³Ø§Ø¹ØªÙŠ ÙˆÙŠÙ† Ø£Ø±Ø¬Ø¹ØŸ Ø¥Ù„ÙŠØ§ ØµØ¯ÙÙ‡ØŸ ÙˆØ§Ù„Ù„Ù‡ ...  negative\n",
       "3     ğŸ’¥ Ø­Ù…Ø¯Ø§ Ù„Ù„Ù‡ .. Ø§Ù„Ù‚ÙŠØ§Ø¯Ø© ÙƒÙ…Ø§ Ù‡ÙŠ ÙˆØ§Ù„Ø§Ø¹Ø¯Ø§Ø¯ ÙÙŠ ØªØ²Ø§ÙŠØ¯...  negative\n",
       "4     #Ø§Ù„Ù‡Ù„Ø§Ù„_Ø§Ù„Ø§Ù‡Ù„ÙŠ Ù…Ø¨Ø±ÙˆÙƒ Ù„Ù„Ù‡Ù„Ø§Ù„ Ù‡Ø§Ø±Ø¯Ù„Ùƒ Ù„Ù„Ø·Ø­Ø§Ù„Ø¨ ğŸ¸ Ùˆ...  negative\n",
       "...                                                 ...       ...\n",
       "4995  Ø£Ø­Ø¨ Ù†ÙØ³ÙƒØŒ Ø£Ø¹Ø´Ù‚Ù‡Ø§ ÙˆØ¯Ù„Ù„Ù‡Ø§ .. ÙØªØ´ Ø¹Ù† Ø§Ù„Ø³Ø¹Ø§Ø¯Ø© Ø³ØªØ¬Ø¯...  positive\n",
       "4996  Ø¨Ù…Ù†Ø§Ø³Ø¨Ø© ÙÙˆØ² Ø§Ù„Ù‡Ù„Ø§Ù„ .. ğŸ’™ Ø³Ø­Ø¨ Ø¹Ù„Ù‰ Ø¢ÙŠÙÙˆÙ† XRğŸ“± Ø±ØªÙˆÙŠ...  positive\n",
       "4997  #ÙˆØ´_ÙŠÙ‚ÙˆÙ„_Ø§Ù„Ù„ÙŠÙ„ ÙŠÙ‚ÙˆÙ„ Ø§Ø±Ù‚Ø¯ÙŠ ÙˆÙÙƒÙŠ Ø§Ù„Ù…Ø³Ù„Ù…ÙŠÙ† Ø´Ø±Ùƒ ğŸŒš ...  positive\n",
       "4998  Ø§Ù„Ù„Ù‡Ù… Ø§Ù†Ùƒ ØªØ±Ù‰ Ù…Ø§ Ù„Ø§ Ù†Ø±Ù‰ ÙˆØªØ¹Ù„Ù… Ù…Ø§ Ù„Ø§ Ù†Ø¹Ù„Ù… ÙØ§ÙƒÙÙ†...  positive\n",
       "4999               [ â˜† ] : ÙˆÙ† Ø°Ø§ Ù†Ø§ÙŠÙ† Ù…Ù† Ø§Ù„ÙØ§Ù†Ù…ÙŠØªÙ†Ù‚ .\\n  positive\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = r'C:\\Users\\DELL\\Desktop\\Specialist\\DataSet\\Sentiment Analysis\\data\\arabic_tweets'\n",
    "data = read_dataset(data_dir, num_samples=5000)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e4b82d",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "bb7033bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt', quiet=True)  # This line downloads the default tokenizer (English)\n",
    "\n",
    "# Now, download the Arabic tokenization model\n",
    "nltk.download('punkt', quiet=True, raise_on_error=True, halt_on_error=False, download_dir=r'~/nltk_data/tokenizers/punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eacffffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ø§Ø¹ØªØ±Ù Ø§Ù† Ø¨ØªØ³ ÙƒØ§Ù†Ùˆ Ø´ÙˆÙŠ Ø´ÙˆÙŠ ÙŠØ¬ÙŠØ¨Ùˆ Ø±Ø§Ø³ÙŠ Ù„ÙƒÙ† Ø§Ù„ÙŠÙˆÙ…...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[Ø§Ø¹ØªØ±Ù, Ø§Ù†, Ø¨ØªØ³, ÙƒØ§Ù†Ùˆ, Ø´ÙˆÙŠ, Ø´ÙˆÙŠ, ÙŠØ¬ÙŠØ¨Ùˆ, Ø±Ø§Ø³ÙŠ, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ØªÙˆÙ‚Ø¹Øª Ø§Ø°Ø§ Ø¬Ø§Øª Ø¯Ø§Ø±ÙŠØ§ Ø¨Ø´ÙˆÙÙ‡Ù… ÙƒØ§Ù…Ù„ÙŠÙ† Ø¨Ø³ Ù„ÙŠ Ù„Ù„Ø­ÙŠÙ† ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[ØªÙˆÙ‚Ø¹Øª, Ø§Ø°Ø§, Ø¬Ø§Øª, Ø¯Ø§Ø±ÙŠØ§, Ø¨Ø´ÙˆÙÙ‡Ù…, ÙƒØ§Ù…Ù„ÙŠÙ†, Ø¨Ø³, Ù„...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ù„Ùˆ Ø¨ÙŠØ¯ÙŠ Ø£Ø±Ø¬Ø¹ Ø³Ø§Ø¹ØªÙŠ ÙˆÙŠÙ† Ø£Ø±Ø¬Ø¹ØŸ Ø¥Ù„ÙŠØ§ ØµØ¯ÙÙ‡ØŸ ÙˆØ§Ù„Ù„Ù‡ ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[Ù„Ùˆ, Ø¨ÙŠØ¯ÙŠ, Ø£Ø±Ø¬Ø¹, Ø³Ø§Ø¹ØªÙŠ, ÙˆÙŠÙ†, Ø£Ø±Ø¬Ø¹ØŸ, Ø¥Ù„ÙŠØ§, ØµØ¯ÙÙ‡...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ğŸ’¥ Ø­Ù…Ø¯Ø§ Ù„Ù„Ù‡ .. Ø§Ù„Ù‚ÙŠØ§Ø¯Ø© ÙƒÙ…Ø§ Ù‡ÙŠ ÙˆØ§Ù„Ø§Ø¹Ø¯Ø§Ø¯ ÙÙŠ ØªØ²Ø§ÙŠØ¯...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[ğŸ’¥, Ø­Ù…Ø¯Ø§, Ù„Ù„Ù‡, .., Ø§Ù„Ù‚ÙŠØ§Ø¯Ø©, ÙƒÙ…Ø§, Ù‡ÙŠ, ÙˆØ§Ù„Ø§Ø¹Ø¯Ø§Ø¯,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#Ø§Ù„Ù‡Ù„Ø§Ù„_Ø§Ù„Ø§Ù‡Ù„ÙŠ Ù…Ø¨Ø±ÙˆÙƒ Ù„Ù„Ù‡Ù„Ø§Ù„ Ù‡Ø§Ø±Ø¯Ù„Ùƒ Ù„Ù„Ø·Ø­Ø§Ù„Ø¨ ğŸ¸ Ùˆ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[#, Ø§Ù„Ù‡Ù„Ø§Ù„_Ø§Ù„Ø§Ù‡Ù„ÙŠ, Ù…Ø¨Ø±ÙˆÙƒ, Ù„Ù„Ù‡Ù„Ø§Ù„, Ù‡Ø§Ø±Ø¯Ù„Ùƒ, Ù„Ù„Ø·Ø­...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>Ø£Ø­Ø¨ Ù†ÙØ³ÙƒØŒ Ø£Ø¹Ø´Ù‚Ù‡Ø§ ÙˆØ¯Ù„Ù„Ù‡Ø§ .. ÙØªØ´ Ø¹Ù† Ø§Ù„Ø³Ø¹Ø§Ø¯Ø© Ø³ØªØ¬Ø¯...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[Ø£Ø­Ø¨, Ù†ÙØ³ÙƒØŒ, Ø£Ø¹Ø´Ù‚Ù‡Ø§, ÙˆØ¯Ù„Ù„Ù‡Ø§, .., ÙØªØ´, Ø¹Ù†, Ø§Ù„Ø³Ø¹...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>Ø¨Ù…Ù†Ø§Ø³Ø¨Ø© ÙÙˆØ² Ø§Ù„Ù‡Ù„Ø§Ù„ .. ğŸ’™ Ø³Ø­Ø¨ Ø¹Ù„Ù‰ Ø¢ÙŠÙÙˆÙ† XRğŸ“± Ø±ØªÙˆÙŠ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[Ø¨Ù…Ù†Ø§Ø³Ø¨Ø©, ÙÙˆØ², Ø§Ù„Ù‡Ù„Ø§Ù„, .., ğŸ’™, Ø³Ø­Ø¨, Ø¹Ù„Ù‰, Ø¢ÙŠÙÙˆÙ†,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>#ÙˆØ´_ÙŠÙ‚ÙˆÙ„_Ø§Ù„Ù„ÙŠÙ„ ÙŠÙ‚ÙˆÙ„ Ø§Ø±Ù‚Ø¯ÙŠ ÙˆÙÙƒÙŠ Ø§Ù„Ù…Ø³Ù„Ù…ÙŠÙ† Ø´Ø±Ùƒ ğŸŒš ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[#, ÙˆØ´_ÙŠÙ‚ÙˆÙ„_Ø§Ù„Ù„ÙŠÙ„, ÙŠÙ‚ÙˆÙ„, Ø§Ø±Ù‚Ø¯ÙŠ, ÙˆÙÙƒÙŠ, Ø§Ù„Ù…Ø³Ù„Ù…ÙŠÙ†...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Ø§Ù„Ù„Ù‡Ù… Ø§Ù†Ùƒ ØªØ±Ù‰ Ù…Ø§ Ù„Ø§ Ù†Ø±Ù‰ ÙˆØªØ¹Ù„Ù… Ù…Ø§ Ù„Ø§ Ù†Ø¹Ù„Ù… ÙØ§ÙƒÙÙ†...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[Ø§Ù„Ù„Ù‡Ù…, Ø§Ù†Ùƒ, ØªØ±Ù‰, Ù…Ø§, Ù„Ø§, Ù†Ø±Ù‰, ÙˆØªØ¹Ù„Ù…, Ù…Ø§, Ù„Ø§, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>[ â˜† ] : ÙˆÙ† Ø°Ø§ Ù†Ø§ÙŠÙ† Ù…Ù† Ø§Ù„ÙØ§Ù†Ù…ÙŠØªÙ†Ù‚ .\\n</td>\n",
       "      <td>positive</td>\n",
       "      <td>[[, â˜†, ], :, ÙˆÙ†, Ø°Ø§, Ù†Ø§ÙŠÙ†, Ù…Ù†, Ø§Ù„ÙØ§Ù†Ù…ÙŠØªÙ†Ù‚, .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text sentiment  \\\n",
       "0     Ø§Ø¹ØªØ±Ù Ø§Ù† Ø¨ØªØ³ ÙƒØ§Ù†Ùˆ Ø´ÙˆÙŠ Ø´ÙˆÙŠ ÙŠØ¬ÙŠØ¨Ùˆ Ø±Ø§Ø³ÙŠ Ù„ÙƒÙ† Ø§Ù„ÙŠÙˆÙ…...  negative   \n",
       "1     ØªÙˆÙ‚Ø¹Øª Ø§Ø°Ø§ Ø¬Ø§Øª Ø¯Ø§Ø±ÙŠØ§ Ø¨Ø´ÙˆÙÙ‡Ù… ÙƒØ§Ù…Ù„ÙŠÙ† Ø¨Ø³ Ù„ÙŠ Ù„Ù„Ø­ÙŠÙ† ...  negative   \n",
       "2     Ù„Ùˆ Ø¨ÙŠØ¯ÙŠ Ø£Ø±Ø¬Ø¹ Ø³Ø§Ø¹ØªÙŠ ÙˆÙŠÙ† Ø£Ø±Ø¬Ø¹ØŸ Ø¥Ù„ÙŠØ§ ØµØ¯ÙÙ‡ØŸ ÙˆØ§Ù„Ù„Ù‡ ...  negative   \n",
       "3     ğŸ’¥ Ø­Ù…Ø¯Ø§ Ù„Ù„Ù‡ .. Ø§Ù„Ù‚ÙŠØ§Ø¯Ø© ÙƒÙ…Ø§ Ù‡ÙŠ ÙˆØ§Ù„Ø§Ø¹Ø¯Ø§Ø¯ ÙÙŠ ØªØ²Ø§ÙŠØ¯...  negative   \n",
       "4     #Ø§Ù„Ù‡Ù„Ø§Ù„_Ø§Ù„Ø§Ù‡Ù„ÙŠ Ù…Ø¨Ø±ÙˆÙƒ Ù„Ù„Ù‡Ù„Ø§Ù„ Ù‡Ø§Ø±Ø¯Ù„Ùƒ Ù„Ù„Ø·Ø­Ø§Ù„Ø¨ ğŸ¸ Ùˆ...  negative   \n",
       "...                                                 ...       ...   \n",
       "4995  Ø£Ø­Ø¨ Ù†ÙØ³ÙƒØŒ Ø£Ø¹Ø´Ù‚Ù‡Ø§ ÙˆØ¯Ù„Ù„Ù‡Ø§ .. ÙØªØ´ Ø¹Ù† Ø§Ù„Ø³Ø¹Ø§Ø¯Ø© Ø³ØªØ¬Ø¯...  positive   \n",
       "4996  Ø¨Ù…Ù†Ø§Ø³Ø¨Ø© ÙÙˆØ² Ø§Ù„Ù‡Ù„Ø§Ù„ .. ğŸ’™ Ø³Ø­Ø¨ Ø¹Ù„Ù‰ Ø¢ÙŠÙÙˆÙ† XRğŸ“± Ø±ØªÙˆÙŠ...  positive   \n",
       "4997  #ÙˆØ´_ÙŠÙ‚ÙˆÙ„_Ø§Ù„Ù„ÙŠÙ„ ÙŠÙ‚ÙˆÙ„ Ø§Ø±Ù‚Ø¯ÙŠ ÙˆÙÙƒÙŠ Ø§Ù„Ù…Ø³Ù„Ù…ÙŠÙ† Ø´Ø±Ùƒ ğŸŒš ...  positive   \n",
       "4998  Ø§Ù„Ù„Ù‡Ù… Ø§Ù†Ùƒ ØªØ±Ù‰ Ù…Ø§ Ù„Ø§ Ù†Ø±Ù‰ ÙˆØªØ¹Ù„Ù… Ù…Ø§ Ù„Ø§ Ù†Ø¹Ù„Ù… ÙØ§ÙƒÙÙ†...  positive   \n",
       "4999               [ â˜† ] : ÙˆÙ† Ø°Ø§ Ù†Ø§ÙŠÙ† Ù…Ù† Ø§Ù„ÙØ§Ù†Ù…ÙŠØªÙ†Ù‚ .\\n  positive   \n",
       "\n",
       "                                                 tokens  \n",
       "0     [Ø§Ø¹ØªØ±Ù, Ø§Ù†, Ø¨ØªØ³, ÙƒØ§Ù†Ùˆ, Ø´ÙˆÙŠ, Ø´ÙˆÙŠ, ÙŠØ¬ÙŠØ¨Ùˆ, Ø±Ø§Ø³ÙŠ, ...  \n",
       "1     [ØªÙˆÙ‚Ø¹Øª, Ø§Ø°Ø§, Ø¬Ø§Øª, Ø¯Ø§Ø±ÙŠØ§, Ø¨Ø´ÙˆÙÙ‡Ù…, ÙƒØ§Ù…Ù„ÙŠÙ†, Ø¨Ø³, Ù„...  \n",
       "2     [Ù„Ùˆ, Ø¨ÙŠØ¯ÙŠ, Ø£Ø±Ø¬Ø¹, Ø³Ø§Ø¹ØªÙŠ, ÙˆÙŠÙ†, Ø£Ø±Ø¬Ø¹ØŸ, Ø¥Ù„ÙŠØ§, ØµØ¯ÙÙ‡...  \n",
       "3     [ğŸ’¥, Ø­Ù…Ø¯Ø§, Ù„Ù„Ù‡, .., Ø§Ù„Ù‚ÙŠØ§Ø¯Ø©, ÙƒÙ…Ø§, Ù‡ÙŠ, ÙˆØ§Ù„Ø§Ø¹Ø¯Ø§Ø¯,...  \n",
       "4     [#, Ø§Ù„Ù‡Ù„Ø§Ù„_Ø§Ù„Ø§Ù‡Ù„ÙŠ, Ù…Ø¨Ø±ÙˆÙƒ, Ù„Ù„Ù‡Ù„Ø§Ù„, Ù‡Ø§Ø±Ø¯Ù„Ùƒ, Ù„Ù„Ø·Ø­...  \n",
       "...                                                 ...  \n",
       "4995  [Ø£Ø­Ø¨, Ù†ÙØ³ÙƒØŒ, Ø£Ø¹Ø´Ù‚Ù‡Ø§, ÙˆØ¯Ù„Ù„Ù‡Ø§, .., ÙØªØ´, Ø¹Ù†, Ø§Ù„Ø³Ø¹...  \n",
       "4996  [Ø¨Ù…Ù†Ø§Ø³Ø¨Ø©, ÙÙˆØ², Ø§Ù„Ù‡Ù„Ø§Ù„, .., ğŸ’™, Ø³Ø­Ø¨, Ø¹Ù„Ù‰, Ø¢ÙŠÙÙˆÙ†,...  \n",
       "4997  [#, ÙˆØ´_ÙŠÙ‚ÙˆÙ„_Ø§Ù„Ù„ÙŠÙ„, ÙŠÙ‚ÙˆÙ„, Ø§Ø±Ù‚Ø¯ÙŠ, ÙˆÙÙƒÙŠ, Ø§Ù„Ù…Ø³Ù„Ù…ÙŠÙ†...  \n",
       "4998  [Ø§Ù„Ù„Ù‡Ù…, Ø§Ù†Ùƒ, ØªØ±Ù‰, Ù…Ø§, Ù„Ø§, Ù†Ø±Ù‰, ÙˆØªØ¹Ù„Ù…, Ù…Ø§, Ù„Ø§, ...  \n",
       "4999      [[, â˜†, ], :, ÙˆÙ†, Ø°Ø§, Ù†Ø§ÙŠÙ†, Ù…Ù†, Ø§Ù„ÙØ§Ù†Ù…ÙŠØªÙ†Ù‚, .]  \n",
       "\n",
       "[5000 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tokens'] = data['text'].apply(tokenize_text)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d9b5b9",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db2f8e7",
   "metadata": {},
   "source": [
    "Arabic punctuation marks and diacritical marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d33fc49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_punctuation = r'[\\u060C\\u061B\\u061F\\u066A\\u066B\\u066C\\u066D\\u06D4\\u06DD\\u06DE\\u06E9\\u06EA\\u06EB\\u06EC\\u06ED\\uFD3E\\uFD3F]'\n",
    "arabic_diacritics = r'[\\u0610-\\u061A\\u064B-\\u065F\\u06D6-\\u06ED]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29411e99",
   "metadata": {},
   "source": [
    "Removal of Punctuation, Diacritical Marks, Numbers, and Non-Arabic Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e4dfdfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ø§Ø¹ØªØ±Ù Ø§Ù† Ø¨ØªØ³ ÙƒØ§Ù†Ùˆ Ø´ÙˆÙŠ Ø´ÙˆÙŠ ÙŠØ¬ÙŠØ¨Ùˆ Ø±Ø§Ø³ÙŠ Ù„ÙƒÙ† Ø§Ù„ÙŠÙˆÙ…...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[Ø§Ø¹ØªØ±Ù, Ø§Ù†, Ø¨ØªØ³, ÙƒØ§Ù†Ùˆ, Ø´ÙˆÙŠ, Ø´ÙˆÙŠ, ÙŠØ¬ÙŠØ¨Ùˆ, Ø±Ø§Ø³ÙŠ, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ØªÙˆÙ‚Ø¹Øª Ø§Ø°Ø§ Ø¬Ø§Øª Ø¯Ø§Ø±ÙŠØ§ Ø¨Ø´ÙˆÙÙ‡Ù… ÙƒØ§Ù…Ù„ÙŠÙ† Ø¨Ø³ Ù„ÙŠ Ù„Ù„Ø­ÙŠÙ† ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[ØªÙˆÙ‚Ø¹Øª, Ø§Ø°Ø§, Ø¬Ø§Øª, Ø¯Ø§Ø±ÙŠØ§, Ø¨Ø´ÙˆÙÙ‡Ù…, ÙƒØ§Ù…Ù„ÙŠÙ†, Ø¨Ø³, Ù„...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ù„Ùˆ Ø¨ÙŠØ¯ÙŠ Ø£Ø±Ø¬Ø¹ Ø³Ø§Ø¹ØªÙŠ ÙˆÙŠÙ† Ø£Ø±Ø¬Ø¹ØŸ Ø¥Ù„ÙŠØ§ ØµØ¯ÙÙ‡ØŸ ÙˆØ§Ù„Ù„Ù‡ ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[Ù„Ùˆ, Ø¨ÙŠØ¯ÙŠ, Ø£Ø±Ø¬Ø¹, Ø³Ø§Ø¹ØªÙŠ, ÙˆÙŠÙ†, Ø£Ø±Ø¬Ø¹, Ø¥Ù„ÙŠØ§, ØµØ¯ÙÙ‡,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ğŸ’¥ Ø­Ù…Ø¯Ø§ Ù„Ù„Ù‡ .. Ø§Ù„Ù‚ÙŠØ§Ø¯Ø© ÙƒÙ…Ø§ Ù‡ÙŠ ÙˆØ§Ù„Ø§Ø¹Ø¯Ø§Ø¯ ÙÙŠ ØªØ²Ø§ÙŠØ¯...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[Ø­Ù…Ø¯Ø§, Ù„Ù„Ù‡, Ø§Ù„Ù‚ÙŠØ§Ø¯Ø©, ÙƒÙ…Ø§, Ù‡ÙŠ, ÙˆØ§Ù„Ø§Ø¹Ø¯Ø§Ø¯, ÙÙŠ, ØªØ²...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#Ø§Ù„Ù‡Ù„Ø§Ù„_Ø§Ù„Ø§Ù‡Ù„ÙŠ Ù…Ø¨Ø±ÙˆÙƒ Ù„Ù„Ù‡Ù„Ø§Ù„ Ù‡Ø§Ø±Ø¯Ù„Ùƒ Ù„Ù„Ø·Ø­Ø§Ù„Ø¨ ğŸ¸ Ùˆ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[Ù…Ø¨Ø±ÙˆÙƒ, Ù„Ù„Ù‡Ù„Ø§Ù„, Ù‡Ø§Ø±Ø¯Ù„Ùƒ, Ù„Ù„Ø·Ø­Ø§Ù„Ø¨, ÙˆØ·Ø², ÙÙŠ, Ø§Ù„Ù†ØµØ±]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>Ø£Ø­Ø¨ Ù†ÙØ³ÙƒØŒ Ø£Ø¹Ø´Ù‚Ù‡Ø§ ÙˆØ¯Ù„Ù„Ù‡Ø§ .. ÙØªØ´ Ø¹Ù† Ø§Ù„Ø³Ø¹Ø§Ø¯Ø© Ø³ØªØ¬Ø¯...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[Ø£Ø­Ø¨, Ù†ÙØ³Ùƒ, Ø£Ø¹Ø´Ù‚Ù‡Ø§, ÙˆØ¯Ù„Ù„Ù‡Ø§, ÙØªØ´, Ø¹Ù†, Ø§Ù„Ø³Ø¹Ø§Ø¯Ø©, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>Ø¨Ù…Ù†Ø§Ø³Ø¨Ø© ÙÙˆØ² Ø§Ù„Ù‡Ù„Ø§Ù„ .. ğŸ’™ Ø³Ø­Ø¨ Ø¹Ù„Ù‰ Ø¢ÙŠÙÙˆÙ† XRğŸ“± Ø±ØªÙˆÙŠ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[Ø¨Ù…Ù†Ø§Ø³Ø¨Ø©, ÙÙˆØ², Ø§Ù„Ù‡Ù„Ø§Ù„, Ø³Ø­Ø¨, Ø¹Ù„Ù‰, Ø¢ÙŠÙÙˆÙ†, Ø±ØªÙˆÙŠØª,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>#ÙˆØ´_ÙŠÙ‚ÙˆÙ„_Ø§Ù„Ù„ÙŠÙ„ ÙŠÙ‚ÙˆÙ„ Ø§Ø±Ù‚Ø¯ÙŠ ÙˆÙÙƒÙŠ Ø§Ù„Ù…Ø³Ù„Ù…ÙŠÙ† Ø´Ø±Ùƒ ğŸŒš ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[ÙŠÙ‚ÙˆÙ„, Ø§Ø±Ù‚Ø¯ÙŠ, ÙˆÙÙƒÙŠ, Ø§Ù„Ù…Ø³Ù„Ù…ÙŠÙ†, Ø´Ø±Ùƒ, Ø¨Ø³, Ø§Ù†Ø§, Ù‚Ù„...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Ø§Ù„Ù„Ù‡Ù… Ø§Ù†Ùƒ ØªØ±Ù‰ Ù…Ø§ Ù„Ø§ Ù†Ø±Ù‰ ÙˆØªØ¹Ù„Ù… Ù…Ø§ Ù„Ø§ Ù†Ø¹Ù„Ù… ÙØ§ÙƒÙÙ†...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[Ø§Ù„Ù„Ù‡Ù…, Ø§Ù†Ùƒ, ØªØ±Ù‰, Ù…Ø§, Ù„Ø§, Ù†Ø±Ù‰, ÙˆØªØ¹Ù„Ù…, Ù…Ø§, Ù„Ø§, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>[ â˜† ] : ÙˆÙ† Ø°Ø§ Ù†Ø§ÙŠÙ† Ù…Ù† Ø§Ù„ÙØ§Ù†Ù…ÙŠØªÙ†Ù‚ .\\n</td>\n",
       "      <td>positive</td>\n",
       "      <td>[ÙˆÙ†, Ø°Ø§, Ù†Ø§ÙŠÙ†, Ù…Ù†, Ø§Ù„ÙØ§Ù†Ù…ÙŠØªÙ†Ù‚]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text sentiment  \\\n",
       "0     Ø§Ø¹ØªØ±Ù Ø§Ù† Ø¨ØªØ³ ÙƒØ§Ù†Ùˆ Ø´ÙˆÙŠ Ø´ÙˆÙŠ ÙŠØ¬ÙŠØ¨Ùˆ Ø±Ø§Ø³ÙŠ Ù„ÙƒÙ† Ø§Ù„ÙŠÙˆÙ…...  negative   \n",
       "1     ØªÙˆÙ‚Ø¹Øª Ø§Ø°Ø§ Ø¬Ø§Øª Ø¯Ø§Ø±ÙŠØ§ Ø¨Ø´ÙˆÙÙ‡Ù… ÙƒØ§Ù…Ù„ÙŠÙ† Ø¨Ø³ Ù„ÙŠ Ù„Ù„Ø­ÙŠÙ† ...  negative   \n",
       "2     Ù„Ùˆ Ø¨ÙŠØ¯ÙŠ Ø£Ø±Ø¬Ø¹ Ø³Ø§Ø¹ØªÙŠ ÙˆÙŠÙ† Ø£Ø±Ø¬Ø¹ØŸ Ø¥Ù„ÙŠØ§ ØµØ¯ÙÙ‡ØŸ ÙˆØ§Ù„Ù„Ù‡ ...  negative   \n",
       "3     ğŸ’¥ Ø­Ù…Ø¯Ø§ Ù„Ù„Ù‡ .. Ø§Ù„Ù‚ÙŠØ§Ø¯Ø© ÙƒÙ…Ø§ Ù‡ÙŠ ÙˆØ§Ù„Ø§Ø¹Ø¯Ø§Ø¯ ÙÙŠ ØªØ²Ø§ÙŠØ¯...  negative   \n",
       "4     #Ø§Ù„Ù‡Ù„Ø§Ù„_Ø§Ù„Ø§Ù‡Ù„ÙŠ Ù…Ø¨Ø±ÙˆÙƒ Ù„Ù„Ù‡Ù„Ø§Ù„ Ù‡Ø§Ø±Ø¯Ù„Ùƒ Ù„Ù„Ø·Ø­Ø§Ù„Ø¨ ğŸ¸ Ùˆ...  negative   \n",
       "...                                                 ...       ...   \n",
       "4995  Ø£Ø­Ø¨ Ù†ÙØ³ÙƒØŒ Ø£Ø¹Ø´Ù‚Ù‡Ø§ ÙˆØ¯Ù„Ù„Ù‡Ø§ .. ÙØªØ´ Ø¹Ù† Ø§Ù„Ø³Ø¹Ø§Ø¯Ø© Ø³ØªØ¬Ø¯...  positive   \n",
       "4996  Ø¨Ù…Ù†Ø§Ø³Ø¨Ø© ÙÙˆØ² Ø§Ù„Ù‡Ù„Ø§Ù„ .. ğŸ’™ Ø³Ø­Ø¨ Ø¹Ù„Ù‰ Ø¢ÙŠÙÙˆÙ† XRğŸ“± Ø±ØªÙˆÙŠ...  positive   \n",
       "4997  #ÙˆØ´_ÙŠÙ‚ÙˆÙ„_Ø§Ù„Ù„ÙŠÙ„ ÙŠÙ‚ÙˆÙ„ Ø§Ø±Ù‚Ø¯ÙŠ ÙˆÙÙƒÙŠ Ø§Ù„Ù…Ø³Ù„Ù…ÙŠÙ† Ø´Ø±Ùƒ ğŸŒš ...  positive   \n",
       "4998  Ø§Ù„Ù„Ù‡Ù… Ø§Ù†Ùƒ ØªØ±Ù‰ Ù…Ø§ Ù„Ø§ Ù†Ø±Ù‰ ÙˆØªØ¹Ù„Ù… Ù…Ø§ Ù„Ø§ Ù†Ø¹Ù„Ù… ÙØ§ÙƒÙÙ†...  positive   \n",
       "4999               [ â˜† ] : ÙˆÙ† Ø°Ø§ Ù†Ø§ÙŠÙ† Ù…Ù† Ø§Ù„ÙØ§Ù†Ù…ÙŠØªÙ†Ù‚ .\\n  positive   \n",
       "\n",
       "                                                 tokens  \n",
       "0     [Ø§Ø¹ØªØ±Ù, Ø§Ù†, Ø¨ØªØ³, ÙƒØ§Ù†Ùˆ, Ø´ÙˆÙŠ, Ø´ÙˆÙŠ, ÙŠØ¬ÙŠØ¨Ùˆ, Ø±Ø§Ø³ÙŠ, ...  \n",
       "1     [ØªÙˆÙ‚Ø¹Øª, Ø§Ø°Ø§, Ø¬Ø§Øª, Ø¯Ø§Ø±ÙŠØ§, Ø¨Ø´ÙˆÙÙ‡Ù…, ÙƒØ§Ù…Ù„ÙŠÙ†, Ø¨Ø³, Ù„...  \n",
       "2     [Ù„Ùˆ, Ø¨ÙŠØ¯ÙŠ, Ø£Ø±Ø¬Ø¹, Ø³Ø§Ø¹ØªÙŠ, ÙˆÙŠÙ†, Ø£Ø±Ø¬Ø¹, Ø¥Ù„ÙŠØ§, ØµØ¯ÙÙ‡,...  \n",
       "3     [Ø­Ù…Ø¯Ø§, Ù„Ù„Ù‡, Ø§Ù„Ù‚ÙŠØ§Ø¯Ø©, ÙƒÙ…Ø§, Ù‡ÙŠ, ÙˆØ§Ù„Ø§Ø¹Ø¯Ø§Ø¯, ÙÙŠ, ØªØ²...  \n",
       "4      [Ù…Ø¨Ø±ÙˆÙƒ, Ù„Ù„Ù‡Ù„Ø§Ù„, Ù‡Ø§Ø±Ø¯Ù„Ùƒ, Ù„Ù„Ø·Ø­Ø§Ù„Ø¨, ÙˆØ·Ø², ÙÙŠ, Ø§Ù„Ù†ØµØ±]  \n",
       "...                                                 ...  \n",
       "4995  [Ø£Ø­Ø¨, Ù†ÙØ³Ùƒ, Ø£Ø¹Ø´Ù‚Ù‡Ø§, ÙˆØ¯Ù„Ù„Ù‡Ø§, ÙØªØ´, Ø¹Ù†, Ø§Ù„Ø³Ø¹Ø§Ø¯Ø©, ...  \n",
       "4996  [Ø¨Ù…Ù†Ø§Ø³Ø¨Ø©, ÙÙˆØ², Ø§Ù„Ù‡Ù„Ø§Ù„, Ø³Ø­Ø¨, Ø¹Ù„Ù‰, Ø¢ÙŠÙÙˆÙ†, Ø±ØªÙˆÙŠØª,...  \n",
       "4997  [ÙŠÙ‚ÙˆÙ„, Ø§Ø±Ù‚Ø¯ÙŠ, ÙˆÙÙƒÙŠ, Ø§Ù„Ù…Ø³Ù„Ù…ÙŠÙ†, Ø´Ø±Ùƒ, Ø¨Ø³, Ø§Ù†Ø§, Ù‚Ù„...  \n",
       "4998  [Ø§Ù„Ù„Ù‡Ù…, Ø§Ù†Ùƒ, ØªØ±Ù‰, Ù…Ø§, Ù„Ø§, Ù†Ø±Ù‰, ÙˆØªØ¹Ù„Ù…, Ù…Ø§, Ù„Ø§, ...  \n",
       "4999                     [ÙˆÙ†, Ø°Ø§, Ù†Ø§ÙŠÙ†, Ù…Ù†, Ø§Ù„ÙØ§Ù†Ù…ÙŠØªÙ†Ù‚]  \n",
       "\n",
       "[5000 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tokens'] = data['text'].apply(lambda x: clean_tokens(tokenize_text(x)))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccfcb4e",
   "metadata": {},
   "source": [
    "# Data representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79279f61",
   "metadata": {},
   "source": [
    "Data representation using BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d4f0199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Ø</th>\n",
       "      <th>ØÙ„ÙŠÙƒ</th>\n",
       "      <th>Ø¡</th>\n",
       "      <th>Ø¢Ø§Ø§Ù‡</th>\n",
       "      <th>Ø¢Ø¨Ø§Ø¦Ù†Ø§</th>\n",
       "      <th>Ø¢Ø¨Ø¯Ø¢Ø¹</th>\n",
       "      <th>Ø¢Ø¨ÙŠÙ‡</th>\n",
       "      <th>Ø¢ØªØ®ÙŠÙ„</th>\n",
       "      <th>Ø¢ØªÙƒØ¨Ø±</th>\n",
       "      <th>...</th>\n",
       "      <th>Ú¯Ù…Ø§Ù†</th>\n",
       "      <th>Ú¾Ø§Ø¯Ø¦</th>\n",
       "      <th>Ú¾Ú¾</th>\n",
       "      <th>Û†</th>\n",
       "      <th>Û†Ø´Ù„ÙˆÙ†</th>\n",
       "      <th>Û†Ù„ÙƒÙ†</th>\n",
       "      <th>Ûˆ</th>\n",
       "      <th>ÛˆØ§Ù„Ù„Ù‡</th>\n",
       "      <th>ÛŒØ¨Ù‚ÛŒ</th>\n",
       "      <th>ÛŒÙˆÙ…</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 17256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Ø  ØÙ„ÙŠÙƒ  Ø¡  Ø¢Ø§Ø§Ù‡  Ø¢Ø¨Ø§Ø¦Ù†Ø§  Ø¢Ø¨Ø¯Ø¢Ø¹  Ø¢Ø¨ÙŠÙ‡  Ø¢ØªØ®ÙŠÙ„  Ø¢ØªÙƒØ¨Ø±  ...  Ú¯Ù…Ø§Ù†  Ú¾Ø§Ø¯Ø¦  \\\n",
       "0     0  0     0  0     0       0      0     0      0      0  ...     0     0   \n",
       "1     0  0     0  0     0       0      0     0      0      0  ...     0     0   \n",
       "2     0  0     0  0     0       0      0     0      0      0  ...     0     0   \n",
       "3     0  0     0  0     0       0      0     0      0      0  ...     0     0   \n",
       "4     0  0     0  0     0       0      0     0      0      0  ...     0     0   \n",
       "...  .. ..   ... ..   ...     ...    ...   ...    ...    ...  ...   ...   ...   \n",
       "4995  0  0     0  0     0       0      0     0      0      0  ...     0     0   \n",
       "4996  0  0     0  0     0       0      0     0      0      0  ...     0     0   \n",
       "4997  0  0     0  0     0       0      0     0      0      0  ...     0     0   \n",
       "4998  0  0     0  0     0       0      0     0      0      0  ...     0     0   \n",
       "4999  0  0     0  0     0       0      0     0      0      0  ...     0     0   \n",
       "\n",
       "      Ú¾Ú¾  Û†  Û†Ø´Ù„ÙˆÙ†  Û†Ù„ÙƒÙ†  Ûˆ  ÛˆØ§Ù„Ù„Ù‡  ÛŒØ¨Ù‚ÛŒ  ÛŒÙˆÙ…  \n",
       "0      0  0      0     0  0      0     0    0  \n",
       "1      0  0      0     0  0      0     0    0  \n",
       "2      0  0      0     0  0      0     0    0  \n",
       "3      0  0      0     0  0      0     0    0  \n",
       "4      0  0      0     0  0      0     0    0  \n",
       "...   .. ..    ...   ... ..    ...   ...  ...  \n",
       "4995   0  0      0     0  0      0     0    0  \n",
       "4996   0  0      0     0  0      0     0    0  \n",
       "4997   0  0      0     0  0      0     0    0  \n",
       "4998   0  0      0     0  0      0     0    0  \n",
       "4999   0  0      0     0  0      0     0    0  \n",
       "\n",
       "[5000 rows x 17256 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_representation, bow_vectorizer = represent_data_with_bow(data)\n",
    "bow_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5dd16a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(preprocessor=<function represent_data_with_bow.<locals>.<lambda> at 0x0000019794D4AC10>,\n",
       "                tokenizer=<function represent_data_with_bow.<locals>.<lambda> at 0x0000019794D4AF70>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51369e28",
   "metadata": {},
   "source": [
    "Data representation using Arabert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3cbdc2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"aubmindlab/bert-base-arabert\")\n",
    "model = AutoModel.from_pretrained(\"aubmindlab/bert-base-arabert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "038ed75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "arabert_embeddings, arabert_words = represent_data_with_arabert(data, tokenizer, model)\n",
    "# arabert_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75e23423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arabert_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1ff638",
   "metadata": {},
   "source": [
    "# Print the most similar words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767fbbbc",
   "metadata": {},
   "source": [
    "BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cde4f64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words to 'Ø§Ù…ØªØ­Ø§Ù†' using BoW:\n",
      "Ù„ØªÙ‚Ø¯ÙŠØ±ÙƒÙ…\n",
      "Ø§Ù†Ù…\n",
      "ØªØ§Ù‰\n",
      "ÙˆØ«Ø¨\n",
      "Ù…Ø§ÙƒÙ†Ø³Ù„Ùˆ\n",
      "Most similar words to 'Ø§Ù„Ø£Ù‡Ù„ÙŠ' using BoW:\n",
      "Ø·Ø±Ø¯\n",
      "Ù„ÙƒØ±Ø©\n",
      "Ø¥Ø°Ù†\n",
      "ÙˆØ§Ù„ØªØºØ§ÙÙ„\n",
      "Ø¥Ù†ØªØ¸Ø§Ø±\n",
      "Most similar words to 'Ø§Ù„Ø§ØªØ­Ø§Ø¯' using BoW:\n",
      "Ù…Ø®ØªÙ„ÙØ§\n",
      "Ù…Ù‡Ø¯Ø¯\n",
      "Ù„Ù„Ø¯ÙˆØ±ÙŠ\n",
      "Ø¨Ø·Ù„Ø§\n",
      "ÙŠØªÙˆØ¬\n"
     ]
    }
   ],
   "source": [
    "words_to_check = [\"Ø§Ù…ØªØ­Ø§Ù†\", \"Ø§Ù„Ø£Ù‡Ù„ÙŠ\", \"Ø§Ù„Ø§ØªØ­Ø§Ø¯\"]\n",
    "for word in words_to_check:\n",
    "    print_similar_words_bow(word, bow_vectorizer, bow_representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d07cf2a",
   "metadata": {},
   "source": [
    "AraBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6595c31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words to 'Ø§Ù…ØªØ­Ø§Ù†':\n",
      "Ø´Ù‡ÙˆØ± ØªØ³ØªØ§Ù‡Ù„ Ø§Ù„Ø²Ø±Ù‚Ø§Ø¡\n",
      "Ø´Ù‡ÙˆØ± ØªØ³ØªØ§Ù‡Ù„ Ø§Ù„Ø²Ø±Ù‚Ø§Ø¡\n",
      "ÙŠ Ø­Ø¸Ùƒ\n",
      "ØµØ­ Ù†ÙˆÙ…ÙŠ\n",
      "Ù„Ù„Ø§Ø³Ù Ø¯ÙˆØ§Ù…\n",
      "Most similar words to 'Ø§Ù„Ø£Ù‡Ù„ÙŠ':\n",
      "Ø§Ù„Ù…Ø·Ø± Ù…Ø´Ø§Ù„Ù„Ù‡\n",
      "Ø®Ø³Ø§Ø±Ø© Ø§Ù„ØªØ¹Ù„ÙŠÙ… ÙÙŠÙ‡Ù…\n",
      "ØµØ¨Ø§Ø§Ø­ Ø§Ù„Ù†ØµØ±\n",
      "Ø§Ù„Ø¬Ùˆ ÙŠÙƒØ³Ù„\n",
      "Ø·ÙÙˆ Ø§Ù„ÙƒÙ‡Ø±Ø¨\n",
      "Most similar words to 'Ø§Ù„Ø§ØªØ­Ø§Ø¯':\n",
      "ØµØ¨Ø§Ø§Ø­ Ø§Ù„Ù†ØµØ±\n",
      "ØµØ¨Ø§Ø­ Ø§Ù„Ø§ØªØ­Ø§Ø¯\n",
      "Ø³Ù…Ø§Ø¹Ø§ØªÙŠ Ø®Ø±Ø¨ÙˆØ§\n",
      "ØªÙŠØ´Ø±Øª Ø§Ù„Ù‚Ø§Ø¦Ø¯\n",
      "Ø·ÙÙˆ Ø§Ù„ÙƒÙ‡Ø±Ø¨\n"
     ]
    }
   ],
   "source": [
    "words_to_check = [\"Ø§Ù…ØªØ­Ø§Ù†\", \"Ø§Ù„Ø£Ù‡Ù„ÙŠ\", \"Ø§Ù„Ø§ØªØ­Ø§Ø¯\"]\n",
    "for word in words_to_check:\n",
    "    print_similar_words(word, arabert_embeddings, arabert_words, tokenizer, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79613435",
   "metadata": {},
   "source": [
    "# Plot and visualize the embedding and their similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30adea8",
   "metadata": {},
   "source": [
    "BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b882e2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot and visualize the embedding and their similarities using BoW\n",
    "visualize_embeddings_bow(words_to_check, bow_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67b6e7b",
   "metadata": {},
   "source": [
    "AraBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a13d011e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_embeddings(words_to_check, arabert_embeddings, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6033be20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and testing sets for Bag-of-Words (BoW) representation\n",
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(\n",
    "    bow_representation, data['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Splitting the data into training and testing sets for AraBERT representation\n",
    "X_train_arabert, X_test_arabert, y_train_arabert, y_test_arabert = train_test_split(\n",
    "    arabert_embeddings, data['sentiment'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a494a4",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "efe2c424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the LabelEncoder\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27432752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bow\n",
    "# Fit and transform the class labels in your training set\n",
    "y_train_encoded_bow = label_encoder.fit_transform(y_train_bow)\n",
    "# Transform the class labels in your test set\n",
    "y_test_encoded_bow = label_encoder.transform(y_test_bow)\n",
    "\n",
    "# arabert\n",
    "# Fit and transform the class labels in your training set\n",
    "y_train_encoded_arabert = label_encoder.transform(y_train_arabert)\n",
    "# Transform the class labels in your test set\n",
    "y_test_encoded_arabert = label_encoder.transform(y_test_arabert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5e8963",
   "metadata": {},
   "source": [
    "# Build the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f032e1f4",
   "metadata": {},
   "source": [
    "# BoW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c85ea9",
   "metadata": {},
   "source": [
    "Artificial Neural Network (ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f14fdb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(4,), random_state=42)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build an artificial neural network\n",
    "ann_model_bow = MLPClassifier(hidden_layer_sizes=(4,), activation='relu', solver='adam', random_state=42)\n",
    "ann_model_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7cdb80",
   "metadata": {},
   "source": [
    "LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f67749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an LSTM model\n",
    "lstm_model_bow = Sequential([\n",
    "    LSTM(64, input_shape=(1, X_train_bow.shape[1])),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f5349b",
   "metadata": {},
   "source": [
    "# AraBERT "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22edc282",
   "metadata": {},
   "source": [
    "Artificial Neural Network (ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "770bd4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(4,), random_state=42)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_model_arabert = MLPClassifier(hidden_layer_sizes=(4,), activation='relu', solver='adam', random_state=42)\n",
    "ann_model_arabert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114a7222",
   "metadata": {},
   "source": [
    "LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5741db2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 768)\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_train_arabert is a list\n",
    "X_train_arabert = np.array(X_train_arabert)  # Convert to NumPy array\n",
    "\n",
    "# Now you can access its shape attribute\n",
    "print(X_train_arabert.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27c68eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape input data for LSTM model\n",
    "X_train_arabert_reshaped = np.expand_dims(X_train_arabert, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e350d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM model for AraBERT representation\n",
    "lstm_model_arabert = Sequential([\n",
    "    LSTM(64, input_shape=(1, X_train_arabert_reshaped.shape[2])),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "901f3d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the LSTM model\n",
    "lstm_model_arabert.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86dc4c2",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6723ebf7",
   "metadata": {},
   "source": [
    "BoW Representation\n",
    "\n",
    "Artificial Neural Network (ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a9ab47e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(4,), random_state=42)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_model_bow.fit(X_train_bow, y_train_encoded_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab724c8",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "647bf9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model_bow.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3fff808b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape input data for LSTM model\n",
    "X_train_bow_reshaped = np.expand_dims(X_train_bow, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b593b197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - accuracy: 0.6006 - loss: 0.6739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x197e9ac0fa0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model_bow.fit(X_train_bow_reshaped, y_train_encoded_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552d58c7",
   "metadata": {},
   "source": [
    "AraBERT Representation\n",
    "\n",
    "Artificial Neural Network (ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "53529450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(4,), random_state=42)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_model_arabert.fit(X_train_arabert, y_train_encoded_arabert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5e5005",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c1475481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.5628 - loss: 0.6801 - val_accuracy: 0.6538 - val_loss: 0.6405\n",
      "Epoch 2/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6489 - loss: 0.6273 - val_accuracy: 0.6350 - val_loss: 0.6535\n",
      "Epoch 3/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6578 - loss: 0.6193 - val_accuracy: 0.6425 - val_loss: 0.6260\n",
      "Epoch 4/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6825 - loss: 0.6016 - val_accuracy: 0.6800 - val_loss: 0.6129\n",
      "Epoch 5/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6895 - loss: 0.5954 - val_accuracy: 0.6587 - val_loss: 0.6254\n",
      "Epoch 6/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7035 - loss: 0.5656 - val_accuracy: 0.6600 - val_loss: 0.6203\n",
      "Epoch 7/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6929 - loss: 0.5682 - val_accuracy: 0.6662 - val_loss: 0.6133\n",
      "Epoch 8/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7321 - loss: 0.5420 - val_accuracy: 0.6600 - val_loss: 0.6580\n",
      "Epoch 9/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7305 - loss: 0.5338 - val_accuracy: 0.6488 - val_loss: 0.6722\n",
      "Epoch 10/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7380 - loss: 0.5286 - val_accuracy: 0.6712 - val_loss: 0.6335\n",
      "Epoch 11/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7502 - loss: 0.5105 - val_accuracy: 0.6488 - val_loss: 0.6256\n",
      "Epoch 12/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7555 - loss: 0.4932 - val_accuracy: 0.6850 - val_loss: 0.6322\n",
      "Epoch 13/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7638 - loss: 0.4740 - val_accuracy: 0.6687 - val_loss: 0.6340\n",
      "Epoch 14/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7673 - loss: 0.4748 - val_accuracy: 0.6812 - val_loss: 0.6137\n",
      "Epoch 15/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7615 - loss: 0.4714 - val_accuracy: 0.6913 - val_loss: 0.6206\n",
      "Epoch 16/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7908 - loss: 0.4402 - val_accuracy: 0.6925 - val_loss: 0.6424\n",
      "Epoch 17/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7926 - loss: 0.4300 - val_accuracy: 0.6825 - val_loss: 0.6260\n",
      "Epoch 18/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7999 - loss: 0.4169 - val_accuracy: 0.6862 - val_loss: 0.6588\n",
      "Epoch 19/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8204 - loss: 0.3994 - val_accuracy: 0.7000 - val_loss: 0.6354\n",
      "Epoch 20/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8391 - loss: 0.3793 - val_accuracy: 0.6812 - val_loss: 0.6581\n",
      "Epoch 21/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8344 - loss: 0.3686 - val_accuracy: 0.6787 - val_loss: 0.6541\n",
      "Epoch 22/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8296 - loss: 0.3737 - val_accuracy: 0.6950 - val_loss: 0.6704\n",
      "Epoch 23/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8373 - loss: 0.3609 - val_accuracy: 0.6925 - val_loss: 0.6982\n",
      "Epoch 24/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8481 - loss: 0.3378 - val_accuracy: 0.6812 - val_loss: 0.6848\n",
      "Epoch 25/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8480 - loss: 0.3336 - val_accuracy: 0.7000 - val_loss: 0.6755\n",
      "Epoch 26/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8546 - loss: 0.3184 - val_accuracy: 0.6837 - val_loss: 0.7070\n",
      "Epoch 27/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8546 - loss: 0.3263 - val_accuracy: 0.6862 - val_loss: 0.7278\n",
      "Epoch 28/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8656 - loss: 0.3085 - val_accuracy: 0.6862 - val_loss: 0.7453\n",
      "Epoch 29/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8838 - loss: 0.2775 - val_accuracy: 0.6913 - val_loss: 0.7312\n",
      "Epoch 30/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8871 - loss: 0.2641 - val_accuracy: 0.6900 - val_loss: 0.7347\n",
      "Epoch 31/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8838 - loss: 0.2649 - val_accuracy: 0.6975 - val_loss: 0.7530\n",
      "Epoch 32/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9065 - loss: 0.2370 - val_accuracy: 0.7088 - val_loss: 0.7356\n",
      "Epoch 33/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9053 - loss: 0.2384 - val_accuracy: 0.6950 - val_loss: 0.7327\n",
      "Epoch 34/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9134 - loss: 0.2367 - val_accuracy: 0.6925 - val_loss: 0.7613\n",
      "Epoch 35/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9000 - loss: 0.2279 - val_accuracy: 0.7075 - val_loss: 0.7570\n",
      "Epoch 36/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9141 - loss: 0.2260 - val_accuracy: 0.7088 - val_loss: 0.7817\n",
      "Epoch 37/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9228 - loss: 0.2004 - val_accuracy: 0.7113 - val_loss: 0.7863\n",
      "Epoch 38/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9320 - loss: 0.1979 - val_accuracy: 0.7125 - val_loss: 0.8068\n",
      "Epoch 39/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9223 - loss: 0.1966 - val_accuracy: 0.7125 - val_loss: 0.7877\n",
      "Epoch 40/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9301 - loss: 0.1904 - val_accuracy: 0.6938 - val_loss: 0.8690\n",
      "Epoch 41/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9332 - loss: 0.1796 - val_accuracy: 0.7075 - val_loss: 0.8000\n",
      "Epoch 42/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9391 - loss: 0.1692 - val_accuracy: 0.7113 - val_loss: 0.8197\n",
      "Epoch 43/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9400 - loss: 0.1636 - val_accuracy: 0.7150 - val_loss: 0.8335\n",
      "Epoch 44/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9391 - loss: 0.1680 - val_accuracy: 0.7100 - val_loss: 0.8263\n",
      "Epoch 45/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9356 - loss: 0.1701 - val_accuracy: 0.7088 - val_loss: 0.8410\n",
      "Epoch 46/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9619 - loss: 0.1309 - val_accuracy: 0.7050 - val_loss: 0.8792\n",
      "Epoch 47/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9496 - loss: 0.1476 - val_accuracy: 0.7088 - val_loss: 0.8602\n",
      "Epoch 48/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9476 - loss: 0.1427 - val_accuracy: 0.7150 - val_loss: 0.8589\n",
      "Epoch 49/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9603 - loss: 0.1285 - val_accuracy: 0.6963 - val_loss: 0.9691\n",
      "Epoch 50/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9498 - loss: 0.1256 - val_accuracy: 0.7225 - val_loss: 0.9257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9460 - loss: 0.1426 - val_accuracy: 0.7138 - val_loss: 0.9290\n",
      "Epoch 52/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9551 - loss: 0.1212 - val_accuracy: 0.6862 - val_loss: 0.9919\n",
      "Epoch 53/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9491 - loss: 0.1328 - val_accuracy: 0.7013 - val_loss: 0.9805\n",
      "Epoch 54/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9662 - loss: 0.1021 - val_accuracy: 0.7038 - val_loss: 0.9738\n",
      "Epoch 55/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9659 - loss: 0.1061 - val_accuracy: 0.7063 - val_loss: 0.9407\n",
      "Epoch 56/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9611 - loss: 0.1070 - val_accuracy: 0.6988 - val_loss: 0.9636\n",
      "Epoch 57/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9598 - loss: 0.1121 - val_accuracy: 0.7125 - val_loss: 0.9727\n",
      "Epoch 58/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9704 - loss: 0.0879 - val_accuracy: 0.6775 - val_loss: 1.0374\n",
      "Epoch 59/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9651 - loss: 0.0998 - val_accuracy: 0.7175 - val_loss: 0.9914\n",
      "Epoch 60/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9732 - loss: 0.0842 - val_accuracy: 0.7075 - val_loss: 1.0335\n",
      "Epoch 61/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9674 - loss: 0.0962 - val_accuracy: 0.7000 - val_loss: 0.9913\n",
      "Epoch 62/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9732 - loss: 0.0880 - val_accuracy: 0.7063 - val_loss: 1.0234\n",
      "Epoch 63/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9639 - loss: 0.0949 - val_accuracy: 0.7025 - val_loss: 1.0651\n",
      "Epoch 64/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9662 - loss: 0.0930 - val_accuracy: 0.7038 - val_loss: 1.0292\n",
      "Epoch 65/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9691 - loss: 0.0931 - val_accuracy: 0.7038 - val_loss: 1.0659\n",
      "Epoch 66/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9701 - loss: 0.0862 - val_accuracy: 0.6975 - val_loss: 1.1008\n",
      "Epoch 67/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9722 - loss: 0.0820 - val_accuracy: 0.6938 - val_loss: 1.1079\n",
      "Epoch 68/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9681 - loss: 0.0808 - val_accuracy: 0.7038 - val_loss: 1.1075\n",
      "Epoch 69/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9729 - loss: 0.0677 - val_accuracy: 0.6963 - val_loss: 1.0740\n",
      "Epoch 70/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9768 - loss: 0.0738 - val_accuracy: 0.6975 - val_loss: 1.1184\n",
      "Epoch 71/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9760 - loss: 0.0750 - val_accuracy: 0.7000 - val_loss: 1.1584\n",
      "Epoch 72/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9792 - loss: 0.0677 - val_accuracy: 0.7025 - val_loss: 1.1566\n",
      "Epoch 73/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9828 - loss: 0.0593 - val_accuracy: 0.7125 - val_loss: 1.1807\n",
      "Epoch 74/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9782 - loss: 0.0651 - val_accuracy: 0.7025 - val_loss: 1.2020\n",
      "Epoch 75/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9799 - loss: 0.0666 - val_accuracy: 0.7100 - val_loss: 1.1720\n",
      "Epoch 76/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9806 - loss: 0.0647 - val_accuracy: 0.7038 - val_loss: 1.1695\n",
      "Epoch 77/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9757 - loss: 0.0675 - val_accuracy: 0.7250 - val_loss: 1.1293\n",
      "Epoch 78/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9776 - loss: 0.0665 - val_accuracy: 0.7138 - val_loss: 1.0725\n",
      "Epoch 79/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9745 - loss: 0.0814 - val_accuracy: 0.6963 - val_loss: 1.1630\n",
      "Epoch 80/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9801 - loss: 0.0588 - val_accuracy: 0.7075 - val_loss: 1.1796\n",
      "Epoch 81/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9789 - loss: 0.0647 - val_accuracy: 0.7025 - val_loss: 1.2116\n",
      "Epoch 82/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9764 - loss: 0.0624 - val_accuracy: 0.6913 - val_loss: 1.1776\n",
      "Epoch 83/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9794 - loss: 0.0635 - val_accuracy: 0.6975 - val_loss: 1.2620\n",
      "Epoch 84/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9781 - loss: 0.0582 - val_accuracy: 0.6875 - val_loss: 1.2519\n",
      "Epoch 85/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9823 - loss: 0.0551 - val_accuracy: 0.7038 - val_loss: 1.2086\n",
      "Epoch 86/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9778 - loss: 0.0625 - val_accuracy: 0.6913 - val_loss: 1.2106\n",
      "Epoch 87/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9774 - loss: 0.0579 - val_accuracy: 0.6787 - val_loss: 1.2663\n",
      "Epoch 88/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9786 - loss: 0.0572 - val_accuracy: 0.7038 - val_loss: 1.2585\n",
      "Epoch 89/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9857 - loss: 0.0441 - val_accuracy: 0.7013 - val_loss: 1.2886\n",
      "Epoch 90/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9764 - loss: 0.0622 - val_accuracy: 0.6975 - val_loss: 1.2617\n",
      "Epoch 91/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9855 - loss: 0.0485 - val_accuracy: 0.6950 - val_loss: 1.2891\n",
      "Epoch 92/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9825 - loss: 0.0540 - val_accuracy: 0.6950 - val_loss: 1.3193\n",
      "Epoch 93/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9800 - loss: 0.0551 - val_accuracy: 0.7013 - val_loss: 1.1917\n",
      "Epoch 94/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9826 - loss: 0.0576 - val_accuracy: 0.7038 - val_loss: 1.2508\n",
      "Epoch 95/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9800 - loss: 0.0595 - val_accuracy: 0.6950 - val_loss: 1.3350\n",
      "Epoch 96/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9774 - loss: 0.0672 - val_accuracy: 0.7100 - val_loss: 1.2845\n",
      "Epoch 97/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9872 - loss: 0.0385 - val_accuracy: 0.6975 - val_loss: 1.3011\n",
      "Epoch 98/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9799 - loss: 0.0561 - val_accuracy: 0.7000 - val_loss: 1.3466\n",
      "Epoch 99/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9866 - loss: 0.0420 - val_accuracy: 0.6862 - val_loss: 1.2835\n",
      "Epoch 100/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9822 - loss: 0.0501 - val_accuracy: 0.7000 - val_loss: 1.2829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x19831660ee0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model_arabert.fit(X_train_arabert_reshaped, y_train_encoded_arabert, epochs=100, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fef4c65",
   "metadata": {},
   "source": [
    "Evaluating\n",
    "\n",
    "Bag-of-Words (BoW) Representation\n",
    "\n",
    "Artificial Neural Network (ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a9d8b4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bow_ann = ann_model_bow.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3bbda631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag-of-Words (BoW) Representation:\n",
      "Accuracy: 0.691\n",
      "Precision: 0.70020964360587\n",
      "Recall: 0.668\n",
      "F1-score: 0.6837256908904811\n"
     ]
    }
   ],
   "source": [
    "accuracy_bow_ann = accuracy_score(y_test_encoded_bow, y_pred_bow_ann)\n",
    "precision_bow_ann = precision_score(y_test_encoded_bow, y_pred_bow_ann)\n",
    "recall_bow_ann = recall_score(y_test_encoded_bow, y_pred_bow_ann)\n",
    "f1_bow_ann = f1_score(y_test_encoded_bow, y_pred_bow_ann)\n",
    "\n",
    "print(\"Bag-of-Words (BoW) Representation:\")\n",
    "print(\"Accuracy:\", accuracy_bow_ann)\n",
    "print(\"Precision:\", precision_bow_ann)\n",
    "print(\"Recall:\", recall_bow_ann)\n",
    "print(\"F1-score:\", f1_bow_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "73fd40b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Bag-of-Words (BoW) Representation:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.71      0.70       500\n",
      "           1       0.70      0.67      0.68       500\n",
      "\n",
      "    accuracy                           0.69      1000\n",
      "   macro avg       0.69      0.69      0.69      1000\n",
      "weighted avg       0.69      0.69      0.69      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate classification report for BoW representation\n",
    "classification_report_bow_ann = classification_report(y_test_encoded_bow, y_pred_bow_ann)\n",
    "print(\"Classification Report for Bag-of-Words (BoW) Representation:\\n\", classification_report_bow_ann)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bd0b81",
   "metadata": {},
   "source": [
    "LSTM model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fad76596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape input data for LSTM model\n",
    "X_test_bow_reshaped = np.expand_dims(X_test_bow, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "791c7d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_bow_lstm = lstm_model_bow.predict(X_test_bow_reshaped).argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4446891a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_encoded_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "002b5b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_bow_lstm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "24b99b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag-of-Words (BoW) Representation:\n",
      "Accuracy: 0.688\n",
      "Precision: 0.7259615384615384\n",
      "Recall: 0.604\n",
      "F1-score: 0.6593886462882096\n"
     ]
    }
   ],
   "source": [
    "accuracy_bow_lstm = accuracy_score(y_test_encoded_bow, y_pred_bow_lstm)\n",
    "precision_bow_lstm = precision_score(y_test_encoded_bow, y_pred_bow_lstm)\n",
    "recall_bow_lstm = recall_score(y_test_encoded_bow, y_pred_bow_lstm)\n",
    "f1_bow_lstm = f1_score(y_test_encoded_bow, y_pred_bow_lstm)\n",
    "\n",
    "print(\"Bag-of-Words (BoW) Representation:\")\n",
    "print(\"Accuracy:\", accuracy_bow_lstm)\n",
    "print(\"Precision:\", precision_bow_lstm)\n",
    "print(\"Recall:\", recall_bow_lstm)\n",
    "print(\"F1-score:\", f1_bow_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "829d2acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Bag-of-Words (BoW) Representation:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.77      0.71       500\n",
      "           1       0.73      0.60      0.66       500\n",
      "\n",
      "    accuracy                           0.69      1000\n",
      "   macro avg       0.69      0.69      0.69      1000\n",
      "weighted avg       0.69      0.69      0.69      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate classification report for BoW representation\n",
    "classification_report_bow_lstm = classification_report(y_test_encoded_bow, y_pred_bow_lstm)\n",
    "print(\"Classification Report for Bag-of-Words (BoW) Representation:\\n\", classification_report_bow_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978a0109",
   "metadata": {},
   "source": [
    "AraBERT Representation\n",
    "\n",
    "Artificial Neural Network (ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bfa1ab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_arabert_ann = ann_model_arabert.predict(X_test_arabert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6cda54f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AraBERT Representation:\n",
      "Accuracy: 0.689\n",
      "Precision: 0.702355460385439\n",
      "Recall: 0.656\n",
      "F1-score: 0.6783867631851085\n"
     ]
    }
   ],
   "source": [
    "accuracy_arabert_ann = accuracy_score(y_test_encoded_arabert, y_pred_arabert_ann)\n",
    "precision_arabert_ann = precision_score(y_test_encoded_arabert, y_pred_arabert_ann)\n",
    "recall_arabert_ann = recall_score(y_test_encoded_arabert, y_pred_arabert_ann)\n",
    "f1_arabert_ann = f1_score(y_test_encoded_arabert, y_pred_arabert_ann)\n",
    "\n",
    "print(\"AraBERT Representation:\")\n",
    "print(\"Accuracy:\", accuracy_arabert_ann)\n",
    "print(\"Precision:\", precision_arabert_ann)\n",
    "print(\"Recall:\", recall_arabert_ann)\n",
    "print(\"F1-score:\", f1_arabert_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "22672f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for AraBERT Representation:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.72      0.70       500\n",
      "           1       0.70      0.66      0.68       500\n",
      "\n",
      "    accuracy                           0.69      1000\n",
      "   macro avg       0.69      0.69      0.69      1000\n",
      "weighted avg       0.69      0.69      0.69      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate classification report for AraBERT representation\n",
    "classification_report_arabert_ann = classification_report(y_test_encoded_arabert, y_pred_arabert_ann)\n",
    "print(\"Classification Report for AraBERT Representation:\\n\", classification_report_arabert_ann)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f8fad7",
   "metadata": {},
   "source": [
    "LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "25bbcef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 768)\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_train_arabert is a list\n",
    "X_test_arabert = np.array(X_test_arabert)  # Convert to NumPy array\n",
    "\n",
    "# Now you can access its shape attribute\n",
    "print(X_train_arabert.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a6afda45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape input data for LSTM model\n",
    "X_test_arabert_reshaped = np.expand_dims(X_test_arabert, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "345d978b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_arabert_lstm = lstm_model_arabert.predict(X_test_arabert_reshaped).argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "78f6e3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arabert Representation:\n",
      "Accuracy: 0.689\n",
      "Precision: 0.6901408450704225\n",
      "Recall: 0.686\n",
      "F1-score: 0.6880641925777332\n"
     ]
    }
   ],
   "source": [
    "accuracy_arabert_lstm = accuracy_score(y_test_encoded_arabert, y_pred_arabert_lstm)\n",
    "precision_arabert_lstm = precision_score(y_test_encoded_arabert, y_pred_arabert_lstm)\n",
    "recall_arabert_lstm = recall_score(y_test_encoded_arabert, y_pred_arabert_lstm)\n",
    "f1_arabert_lstm = f1_score(y_test_encoded_arabert, y_pred_arabert_lstm)\n",
    "\n",
    "print(\"Arabert Representation:\")\n",
    "print(\"Accuracy:\", accuracy_arabert_lstm)\n",
    "print(\"Precision:\", precision_arabert_lstm)\n",
    "print(\"Recall:\", recall_arabert_lstm)\n",
    "print(\"F1-score:\", f1_arabert_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "df2c1f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Arabert Representation:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69       500\n",
      "           1       0.69      0.69      0.69       500\n",
      "\n",
      "    accuracy                           0.69      1000\n",
      "   macro avg       0.69      0.69      0.69      1000\n",
      "weighted avg       0.69      0.69      0.69      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate classification report for arabert representation\n",
    "classification_report_arabert_lstm = classification_report(y_test_encoded_arabert, y_pred_arabert_lstm)\n",
    "print(\"Classification Report for Arabert Representation:\\n\", classification_report_arabert_lstm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
